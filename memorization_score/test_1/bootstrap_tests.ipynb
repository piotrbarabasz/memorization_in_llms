{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adb181ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import bootstrap\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9e8fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27 files\n"
     ]
    }
   ],
   "source": [
    "# ROOT_DIR = Path(\"C:/Users/user/Desktop/pb_msc/llm_judge/results_new_rag_llama_3_3/\")\n",
    "ROOT_DIR = Path(\"C:/Users/user/Desktop/MSc/pb_msc/llm_judge/results_llm_retrival_reranker_llama_3_3/\")\n",
    "\n",
    "file_paths = sorted(ROOT_DIR.rglob(\"judgements_*.json\"))\n",
    "\n",
    "print(f\"Found {len(file_paths)} files\")\n",
    "# file_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08178ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid questions loaded: 2700\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>model</th>\n",
       "      <th>rag_type</th>\n",
       "      <th>bucket</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>good</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>baseline_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>baseline_rag</td>\n",
       "      <td>good</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>baseline_rag</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>good</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>llama_2_7b_hf</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>llama_2_7b_hf</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>good</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>llama_2_7b_hf</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>llama_2_7b_hf</td>\n",
       "      <td>baseline_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>llama_2_7b_hf</td>\n",
       "      <td>baseline_rag</td>\n",
       "      <td>good</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>llama_2_7b_hf</td>\n",
       "      <td>baseline_rag</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>llama_2_7b_hf</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>llama_2_7b_hf</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>good</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>llama_2_7b_hf</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>mistral-7b_v01</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>mistral-7b_v01</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>good</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>mistral-7b_v01</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>mistral-7b_v01</td>\n",
       "      <td>baseline_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>mistral-7b_v01</td>\n",
       "      <td>baseline_rag</td>\n",
       "      <td>good</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>mistral-7b_v01</td>\n",
       "      <td>baseline_rag</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>mistral-7b_v01</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>mistral-7b_v01</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>good</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...</td>\n",
       "      <td>mistral-7b_v01</td>\n",
       "      <td>naive_rag</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file            model  \\\n",
       "0   C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...  deepseek_llm_7b   \n",
       "1   C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...  deepseek_llm_7b   \n",
       "2   C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...  deepseek_llm_7b   \n",
       "3   C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...  deepseek_llm_7b   \n",
       "4   C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...  deepseek_llm_7b   \n",
       "5   C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...  deepseek_llm_7b   \n",
       "6   C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...  deepseek_llm_7b   \n",
       "7   C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...  deepseek_llm_7b   \n",
       "8   C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...  deepseek_llm_7b   \n",
       "9   C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...    llama_2_7b_hf   \n",
       "10  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...    llama_2_7b_hf   \n",
       "11  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...    llama_2_7b_hf   \n",
       "12  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...    llama_2_7b_hf   \n",
       "13  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...    llama_2_7b_hf   \n",
       "14  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...    llama_2_7b_hf   \n",
       "15  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...    llama_2_7b_hf   \n",
       "16  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...    llama_2_7b_hf   \n",
       "17  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...    llama_2_7b_hf   \n",
       "18  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...   mistral-7b_v01   \n",
       "19  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...   mistral-7b_v01   \n",
       "20  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...   mistral-7b_v01   \n",
       "21  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...   mistral-7b_v01   \n",
       "22  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...   mistral-7b_v01   \n",
       "23  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...   mistral-7b_v01   \n",
       "24  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...   mistral-7b_v01   \n",
       "25  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...   mistral-7b_v01   \n",
       "26  C:\\Users\\user\\Desktop\\MSc\\pb_msc\\llm_judge\\res...   mistral-7b_v01   \n",
       "\n",
       "        rag_type   bucket  n_questions  \n",
       "0   advanced_rag  average          100  \n",
       "1   advanced_rag     good          100  \n",
       "2   advanced_rag     poor          100  \n",
       "3   baseline_rag  average          100  \n",
       "4   baseline_rag     good          100  \n",
       "5   baseline_rag     poor          100  \n",
       "6      naive_rag  average          100  \n",
       "7      naive_rag     good          100  \n",
       "8      naive_rag     poor          100  \n",
       "9   advanced_rag  average          100  \n",
       "10  advanced_rag     good          100  \n",
       "11  advanced_rag     poor          100  \n",
       "12  baseline_rag  average          100  \n",
       "13  baseline_rag     good          100  \n",
       "14  baseline_rag     poor          100  \n",
       "15     naive_rag  average          100  \n",
       "16     naive_rag     good          100  \n",
       "17     naive_rag     poor          100  \n",
       "18  advanced_rag  average          100  \n",
       "19  advanced_rag     good          100  \n",
       "20  advanced_rag     poor          100  \n",
       "21  baseline_rag  average          100  \n",
       "22  baseline_rag     good          100  \n",
       "23  baseline_rag     poor          100  \n",
       "24     naive_rag  average          100  \n",
       "25     naive_rag     good          100  \n",
       "26     naive_rag     poor          100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def parse_filename_simple(p):\n",
    "    name = p.stem\n",
    "    parts = name.split(\"_\")\n",
    "\n",
    "    if parts[0] == \"judgements\":\n",
    "        parts = parts[1:]\n",
    "\n",
    "    bucket = parts[-1]\n",
    "    rag_type = \"_\".join(parts[-3:-1])\n",
    "    model = \"_\".join(parts[:-3])\n",
    "\n",
    "    return model, rag_type, bucket\n",
    "\n",
    "\n",
    "rows = []\n",
    "all_items = []\n",
    "\n",
    "for p in file_paths:\n",
    "    try:\n",
    "        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        n_items = len(data) if isinstance(data, list) else 0\n",
    "        model, rag_type, bucket = parse_filename_simple(p)\n",
    "\n",
    "        rows.append({\n",
    "            \"file\": str(p),\n",
    "            \"model\": model,\n",
    "            \"rag_type\": rag_type,\n",
    "            \"bucket\": bucket,\n",
    "            \"n_questions\": n_items\n",
    "        })\n",
    "\n",
    "        if isinstance(data, list) and n_items > 0:\n",
    "            all_items.extend(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        rows.append({\n",
    "            \"file\": str(p),\n",
    "            \"model\": None,\n",
    "            \"rag_type\": None,\n",
    "            \"bucket\": None,\n",
    "            \"n_questions\": 0\n",
    "        })\n",
    "\n",
    "\n",
    "df_file_overview = pd.DataFrame(rows)\n",
    "\n",
    "print(\"Total valid questions loaded:\", len(all_items))\n",
    "display(df_file_overview.sort_values([\"model\", \"rag_type\", \"bucket\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "413bfc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long DF shape: (24300, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model</th>\n",
       "      <th>rag_method</th>\n",
       "      <th>bucket</th>\n",
       "      <th>question_type</th>\n",
       "      <th>criterion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>335</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>comprehension</td>\n",
       "      <td>correctness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>comprehension</td>\n",
       "      <td>relevance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>335</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>comprehension</td>\n",
       "      <td>completeness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>335</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>analytical</td>\n",
       "      <td>correctness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>335</td>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>analytical</td>\n",
       "      <td>relevance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id            model    rag_method   bucket  question_type  \\\n",
       "0          335  deepseek_llm_7b  advanced_rag  average  comprehension   \n",
       "1          335  deepseek_llm_7b  advanced_rag  average  comprehension   \n",
       "2          335  deepseek_llm_7b  advanced_rag  average  comprehension   \n",
       "3          335  deepseek_llm_7b  advanced_rag  average     analytical   \n",
       "4          335  deepseek_llm_7b  advanced_rag  average     analytical   \n",
       "\n",
       "      criterion  score  \n",
       "0   correctness      1  \n",
       "1     relevance      1  \n",
       "2  completeness      1  \n",
       "3   correctness      1  \n",
       "4     relevance      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def json_to_long_df(items):\n",
    "    rows = []\n",
    "    for it in items:\n",
    "        qid = it[\"id\"]\n",
    "        model = it[\"model\"]\n",
    "        rag = it[\"rag_method\"]\n",
    "        bucket = it[\"bucket\"]\n",
    "\n",
    "        for j in it[\"judgements\"]:\n",
    "            qtype = j[\"question_type\"]\n",
    "            for criterion in [\"correctness\", \"relevance\", \"completeness\"]:\n",
    "                rows.append({\n",
    "                    \"question_id\": qid,\n",
    "                    \"model\": model,\n",
    "                    \"rag_method\": rag,\n",
    "                    \"bucket\": bucket,\n",
    "                    \"question_type\": qtype,\n",
    "                    \"criterion\": criterion,\n",
    "                    \"score\": int(j[criterion]),  # 0/1\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_long = json_to_long_df(all_items)\n",
    "\n",
    "print(\"Long DF shape:\", df_long.shape)\n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efc15af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results shape: (243, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rag_method</th>\n",
       "      <th>question_type</th>\n",
       "      <th>criterion</th>\n",
       "      <th>bucket_pair</th>\n",
       "      <th>bucket_1</th>\n",
       "      <th>bucket_2</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>diff</th>\n",
       "      <th>ratio</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>p_value_one_sided</th>\n",
       "      <th>p_value_two_sided</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>analytical</td>\n",
       "      <td>completeness</td>\n",
       "      <td>good_vs_average</td>\n",
       "      <td>good</td>\n",
       "      <td>average</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.61920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>analytical</td>\n",
       "      <td>completeness</td>\n",
       "      <td>good_vs_poor</td>\n",
       "      <td>good</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.58240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>analytical</td>\n",
       "      <td>completeness</td>\n",
       "      <td>average_vs_poor</td>\n",
       "      <td>average</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.63185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>analytical</td>\n",
       "      <td>correctness</td>\n",
       "      <td>good_vs_average</td>\n",
       "      <td>good</td>\n",
       "      <td>average</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.58105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>analytical</td>\n",
       "      <td>correctness</td>\n",
       "      <td>good_vs_poor</td>\n",
       "      <td>good</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.61430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>analytical</td>\n",
       "      <td>correctness</td>\n",
       "      <td>average_vs_poor</td>\n",
       "      <td>average</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.63115</td>\n",
       "      <td>0.63115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>analytical</td>\n",
       "      <td>relevance</td>\n",
       "      <td>good_vs_average</td>\n",
       "      <td>good</td>\n",
       "      <td>average</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>analytical</td>\n",
       "      <td>relevance</td>\n",
       "      <td>good_vs_poor</td>\n",
       "      <td>good</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>analytical</td>\n",
       "      <td>relevance</td>\n",
       "      <td>average_vs_poor</td>\n",
       "      <td>average</td>\n",
       "      <td>poor</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>comprehension</td>\n",
       "      <td>completeness</td>\n",
       "      <td>good_vs_average</td>\n",
       "      <td>good</td>\n",
       "      <td>average</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.63160</td>\n",
       "      <td>0.63160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model    rag_method  question_type     criterion  \\\n",
       "0  deepseek_llm_7b  advanced_rag     analytical  completeness   \n",
       "1  deepseek_llm_7b  advanced_rag     analytical  completeness   \n",
       "2  deepseek_llm_7b  advanced_rag     analytical  completeness   \n",
       "3  deepseek_llm_7b  advanced_rag     analytical   correctness   \n",
       "4  deepseek_llm_7b  advanced_rag     analytical   correctness   \n",
       "5  deepseek_llm_7b  advanced_rag     analytical   correctness   \n",
       "6  deepseek_llm_7b  advanced_rag     analytical     relevance   \n",
       "7  deepseek_llm_7b  advanced_rag     analytical     relevance   \n",
       "8  deepseek_llm_7b  advanced_rag     analytical     relevance   \n",
       "9  deepseek_llm_7b  advanced_rag  comprehension  completeness   \n",
       "\n",
       "       bucket_pair bucket_1 bucket_2   n1   n2    p1    p2  diff     ratio  \\\n",
       "0  good_vs_average     good  average  100  100  0.97  0.99 -0.02  0.979798   \n",
       "1     good_vs_poor     good     poor  100  100  0.97  1.00 -0.03  0.970000   \n",
       "2  average_vs_poor  average     poor  100  100  0.99  1.00 -0.01  0.990000   \n",
       "3  good_vs_average     good  average  100  100  0.97  1.00 -0.03  0.970000   \n",
       "4     good_vs_poor     good     poor  100  100  0.97  0.99 -0.02  0.979798   \n",
       "5  average_vs_poor  average     poor  100  100  1.00  0.99  0.01  1.010101   \n",
       "6  good_vs_average     good  average  100  100  1.00  1.00  0.00  1.000000   \n",
       "7     good_vs_poor     good     poor  100  100  1.00  1.00  0.00  1.000000   \n",
       "8  average_vs_poor  average     poor  100  100  1.00  1.00  0.00  1.000000   \n",
       "9  good_vs_average     good  average  100  100  1.00  0.99  0.01  1.010101   \n",
       "\n",
       "   ci_low  ci_high  p_value_one_sided  p_value_two_sided  \n",
       "0   -0.06     0.02            1.00000            0.61920  \n",
       "1   -0.07     0.00            1.00000            0.58240  \n",
       "2   -0.03     0.00            1.00000            0.63185  \n",
       "3   -0.07     0.00            1.00000            0.58105  \n",
       "4   -0.06     0.02            1.00000            0.61430  \n",
       "5    0.00     0.03            0.63115            0.63115  \n",
       "6    0.00     0.00            1.00000            1.00000  \n",
       "7    0.00     0.00            1.00000            1.00000  \n",
       "8    0.00     0.00            1.00000            1.00000  \n",
       "9    0.00     0.03            0.63160            0.63160  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def diff_mean(a, b):\n",
    "    return np.mean(a) - np.mean(b)\n",
    "\n",
    "def bootstrap_diff_ratio_scipy(scores_a, scores_b, n_boot=20000, ci=0.95, random_state=42):\n",
    "    scores_a = np.asarray(scores_a)\n",
    "    scores_b = np.asarray(scores_b)\n",
    "\n",
    "    p1_obs = scores_a.mean()\n",
    "    p2_obs = scores_b.mean()\n",
    "    obs_diff = p1_obs - p2_obs\n",
    "    obs_ratio = p1_obs / p2_obs if p2_obs > 0 else np.inf\n",
    "\n",
    "    res = bootstrap(\n",
    "        data=(scores_a, scores_b),\n",
    "        statistic=diff_mean,\n",
    "        n_resamples=n_boot,\n",
    "        vectorized=False,\n",
    "        paired=True,\n",
    "        confidence_level=ci,\n",
    "        method=\"percentile\",\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    ci_low = float(res.confidence_interval.low)\n",
    "    ci_high = float(res.confidence_interval.high)\n",
    "    boot_diffs = res.bootstrap_distribution\n",
    "    \n",
    "    # one sided p-value\n",
    "    if obs_diff > 0:\n",
    "        p_value_one_sided = float(np.mean(boot_diffs >= obs_diff))\n",
    "    else:\n",
    "        p_value_one_sided = 1.0\n",
    "\n",
    "    #two sided p-value\n",
    "    p_value_two_sided  = float(np.mean(np.abs(boot_diffs) >= np.abs(obs_diff)))\n",
    "\n",
    "    return {\n",
    "        \"n1\": len(scores_a),\n",
    "        \"n2\": len(scores_b),\n",
    "        \"p1\": p1_obs,\n",
    "        \"p2\": p2_obs,\n",
    "        \"diff\": obs_diff,\n",
    "        \"ratio\": obs_ratio,\n",
    "        \"ci_low\": ci_low,\n",
    "        \"ci_high\": ci_high,\n",
    "        \"p_value_one_sided\": p_value_one_sided,\n",
    "        \"p_value_two_sided\": p_value_two_sided,\n",
    "    }\n",
    "\n",
    "def run_full_bootstrap(df_long, n_boot=20000, ci=0.95, random_state=42):\n",
    "    bucket_pairs = [(\"good\", \"average\"), (\"good\", \"poor\"), (\"average\", \"poor\")]\n",
    "    group_cols = [\"model\", \"rag_method\", \"question_type\", \"criterion\"]\n",
    "\n",
    "    out_rows = []\n",
    "\n",
    "    for keys, df_g in df_long.groupby(group_cols):\n",
    "        key_dict = dict(zip(group_cols, keys))\n",
    "\n",
    "        bucket2scores = {\n",
    "            b: df_g[df_g[\"bucket\"] == b][\"score\"].values\n",
    "            for b in df_g[\"bucket\"].unique()\n",
    "        }\n",
    "\n",
    "        for b1, b2 in bucket_pairs:\n",
    "            if b1 not in bucket2scores or b2 not in bucket2scores:\n",
    "                continue\n",
    "\n",
    "            res = bootstrap_diff_ratio_scipy(\n",
    "                bucket2scores[b1],\n",
    "                bucket2scores[b2],\n",
    "                n_boot=n_boot,\n",
    "                ci=ci,\n",
    "                random_state=random_state\n",
    "            )\n",
    "\n",
    "            out_rows.append({\n",
    "                **key_dict,\n",
    "                \"bucket_pair\": f\"{b1}_vs_{b2}\",\n",
    "                \"bucket_1\": b1,\n",
    "                \"bucket_2\": b2,\n",
    "                **res\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "df_boot = run_full_bootstrap(df_long, n_boot=20000, ci=0.95, random_state=42)\n",
    "\n",
    "print(\"Bootstrap results shape:\", df_boot.shape)\n",
    "df_boot.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d2c91d",
   "metadata": {},
   "source": [
    "# Continuous per-question scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9654949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous per-question DF shape: (8100, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rag_method</th>\n",
       "      <th>bucket</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question_id</th>\n",
       "      <th>score_cont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>analytical</td>\n",
       "      <td>335</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>analytical</td>\n",
       "      <td>828</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>analytical</td>\n",
       "      <td>1270</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>analytical</td>\n",
       "      <td>1408</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>average</td>\n",
       "      <td>analytical</td>\n",
       "      <td>1418</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model    rag_method   bucket question_type  question_id  \\\n",
       "0  deepseek_llm_7b  advanced_rag  average    analytical          335   \n",
       "1  deepseek_llm_7b  advanced_rag  average    analytical          828   \n",
       "2  deepseek_llm_7b  advanced_rag  average    analytical         1270   \n",
       "3  deepseek_llm_7b  advanced_rag  average    analytical         1408   \n",
       "4  deepseek_llm_7b  advanced_rag  average    analytical         1418   \n",
       "\n",
       "   score_cont  \n",
       "0         1.0  \n",
       "1         1.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_question = (\n",
    "    df_long\n",
    "    .groupby([\"model\", \"rag_method\", \"bucket\", \"question_type\", \"question_id\"], as_index=False)\n",
    "    .agg(score_cont=(\"score\", \"mean\"))\n",
    ")\n",
    "\n",
    "print(\"Continuous per-question DF shape:\", df_question.shape)\n",
    "display(df_question.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8db082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_mean(a, b):\n",
    "    \"\"\"Return mean difference a - b.\"\"\"\n",
    "    return np.mean(a) - np.mean(b)\n",
    "\n",
    "\n",
    "def bootstrap_continuous_bca(scores_a, scores_b, n_boot=100000, ci=0.95, random_state=42):\n",
    "    scores_a = np.asarray(scores_a)\n",
    "    scores_b = np.asarray(scores_b)\n",
    "\n",
    "    p1 = scores_a.mean()\n",
    "    p2 = scores_b.mean()\n",
    "    obs_diff = p1 - p2\n",
    "\n",
    "    res = bootstrap(\n",
    "        data=(scores_a, scores_b),\n",
    "        statistic=diff_mean,\n",
    "        vectorized=False,\n",
    "        paired=False,\n",
    "        n_resamples=n_boot,\n",
    "        confidence_level=ci,\n",
    "        method=\"percentile\",\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    ci_low = float(res.confidence_interval.low)\n",
    "    ci_high = float(res.confidence_interval.high)\n",
    "    boot_diffs = res.bootstrap_distribution\n",
    "\n",
    "    p_value_one_sided = float(np.mean(boot_diffs >= obs_diff))\n",
    "\n",
    "    return {\n",
    "        \"n1\": len(scores_a),\n",
    "        \"n2\": len(scores_b),\n",
    "        \"p1\": p1,\n",
    "        \"p2\": p2,\n",
    "        \"diff\": obs_diff,\n",
    "        \"ratio\": p1 / p2 if p2 > 0 else np.inf,\n",
    "        \"ci_low\": ci_low,\n",
    "        \"ci_high\": ci_high,\n",
    "        \"p_value_one_sided\": p_value_one_sided,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d954d6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final continuous bootstrap results: (27, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rag_method</th>\n",
       "      <th>question_type</th>\n",
       "      <th>bucket_pair</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>diff</th>\n",
       "      <th>ratio</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>p_value_one_sided</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>analytical</td>\n",
       "      <td>good_vs_poor</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>0.983278</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.51211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>comprehension</td>\n",
       "      <td>good_vs_poor</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>advanced_rag</td>\n",
       "      <td>textual_stylistic</td>\n",
       "      <td>good_vs_poor</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.063333</td>\n",
       "      <td>1.070111</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.48888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>baseline_rag</td>\n",
       "      <td>analytical</td>\n",
       "      <td>good_vs_poor</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>0.964143</td>\n",
       "      <td>-0.103333</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>0.49781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepseek_llm_7b</td>\n",
       "      <td>baseline_rag</td>\n",
       "      <td>comprehension</td>\n",
       "      <td>good_vs_poor</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>1.037209</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.49047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model    rag_method      question_type   bucket_pair   n1   n2  \\\n",
       "0  deepseek_llm_7b  advanced_rag         analytical  good_vs_poor  100  100   \n",
       "1  deepseek_llm_7b  advanced_rag      comprehension  good_vs_poor  100  100   \n",
       "2  deepseek_llm_7b  advanced_rag  textual_stylistic  good_vs_poor  100  100   \n",
       "3  deepseek_llm_7b  baseline_rag         analytical  good_vs_poor  100  100   \n",
       "4  deepseek_llm_7b  baseline_rag      comprehension  good_vs_poor  100  100   \n",
       "\n",
       "         p1        p2      diff     ratio    ci_low   ci_high  \\\n",
       "0  0.980000  0.996667 -0.016667  0.983278 -0.033333  0.000000   \n",
       "1  0.996667  1.000000 -0.003333  0.996667 -0.010000  0.000000   \n",
       "2  0.966667  0.903333  0.063333  1.070111  0.023333  0.103333   \n",
       "3  0.806667  0.836667 -0.030000  0.964143 -0.103333  0.043333   \n",
       "4  0.743333  0.716667  0.026667  1.037209 -0.066667  0.120000   \n",
       "\n",
       "   p_value_one_sided  \n",
       "0            0.51211  \n",
       "1            0.49902  \n",
       "2            0.48888  \n",
       "3            0.49781  \n",
       "4            0.49047  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_bootstrap_continuous(df_question, n_boot=100000, ci=0.95, random_state=42):\n",
    "    bucket_1 = \"good\"\n",
    "    bucket_2 = \"poor\"\n",
    "\n",
    "    out_rows = []\n",
    "    group_cols = [\"model\", \"rag_method\", \"question_type\"]\n",
    "\n",
    "    for keys, df_g in df_question.groupby(group_cols):\n",
    "        key_dict = dict(zip(group_cols, keys))\n",
    "\n",
    "        df_b1 = df_g[df_g[\"bucket\"] == bucket_1][\"score_cont\"].values\n",
    "        df_b2 = df_g[df_g[\"bucket\"] == bucket_2][\"score_cont\"].values\n",
    "\n",
    "        res = bootstrap_continuous_bca(\n",
    "            df_b1, df_b2,\n",
    "            n_boot=n_boot,\n",
    "            ci=ci,\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "        out_rows.append({\n",
    "            **key_dict,\n",
    "            \"bucket_pair\": f\"{bucket_1}_vs_{bucket_2}\",\n",
    "            **res\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "\n",
    "df_boot_cont = run_bootstrap_continuous(df_question)\n",
    "\n",
    "print(\"Final continuous bootstrap results:\", df_boot_cont.shape)\n",
    "display(df_boot_cont.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae4b0492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved both sheets to: bootstrap_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "output_path = \"bootstrap_results.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    df_boot.to_excel(writer, index=False, sheet_name=\"per_criterion_results\")\n",
    "    df_boot_cont.to_excel(writer, index=False, sheet_name=\"per_question_results\")\n",
    "\n",
    "print(f\"Saved both sheets to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
